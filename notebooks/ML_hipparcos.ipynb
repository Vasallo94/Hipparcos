{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../data/selected_data.parquet')\n",
    "df = df.dropna(subset=['Tipo_espectral']) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer dos modelos diferentes, uno para crear un modelo que clasifique por tipo espectral y otro por clase espectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vmag</th>\n",
       "      <th>RAdeg</th>\n",
       "      <th>DEdeg</th>\n",
       "      <th>Plx</th>\n",
       "      <th>pmRA</th>\n",
       "      <th>pmDE</th>\n",
       "      <th>DE:RA</th>\n",
       "      <th>BTmag</th>\n",
       "      <th>VTmag</th>\n",
       "      <th>B-V</th>\n",
       "      <th>V-I</th>\n",
       "      <th>Hpmag</th>\n",
       "      <th>(V-I)red</th>\n",
       "      <th>d</th>\n",
       "      <th>T</th>\n",
       "      <th>M_v</th>\n",
       "      <th>M_Hip</th>\n",
       "      <th>Tipo_espectral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.13</td>\n",
       "      <td>38.205924</td>\n",
       "      <td>61.378360</td>\n",
       "      <td>1.47</td>\n",
       "      <td>-2.340000</td>\n",
       "      <td>-0.720000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>8.9100</td>\n",
       "      <td>8.223000</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.70</td>\n",
       "      <td>8.2639</td>\n",
       "      <td>0.66</td>\n",
       "      <td>680.272095</td>\n",
       "      <td>5693.333496</td>\n",
       "      <td>-1.033413</td>\n",
       "      <td>-0.899513</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.46</td>\n",
       "      <td>38.335785</td>\n",
       "      <td>61.521721</td>\n",
       "      <td>2.13</td>\n",
       "      <td>-0.080000</td>\n",
       "      <td>-2.360000</td>\n",
       "      <td>-0.170000</td>\n",
       "      <td>8.8750</td>\n",
       "      <td>8.493000</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.42</td>\n",
       "      <td>8.5436</td>\n",
       "      <td>0.41</td>\n",
       "      <td>469.483582</td>\n",
       "      <td>6960.065430</td>\n",
       "      <td>0.101898</td>\n",
       "      <td>0.185498</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.85</td>\n",
       "      <td>168.619473</td>\n",
       "      <td>-61.344204</td>\n",
       "      <td>10.99</td>\n",
       "      <td>-65.702143</td>\n",
       "      <td>-6.615714</td>\n",
       "      <td>0.142143</td>\n",
       "      <td>9.1995</td>\n",
       "      <td>8.393071</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.94</td>\n",
       "      <td>9.0175</td>\n",
       "      <td>0.94</td>\n",
       "      <td>90.991814</td>\n",
       "      <td>4694.887207</td>\n",
       "      <td>4.054989</td>\n",
       "      <td>4.222488</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.21</td>\n",
       "      <td>120.896126</td>\n",
       "      <td>-40.003188</td>\n",
       "      <td>2.33</td>\n",
       "      <td>-30.820000</td>\n",
       "      <td>16.770000</td>\n",
       "      <td>-0.070000</td>\n",
       "      <td>1.9570</td>\n",
       "      <td>2.189000</td>\n",
       "      <td>-0.269</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>2.1364</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>429.184540</td>\n",
       "      <td>14328.858398</td>\n",
       "      <td>-5.953221</td>\n",
       "      <td>-6.026821</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.55</td>\n",
       "      <td>303.138025</td>\n",
       "      <td>40.268185</td>\n",
       "      <td>1.85</td>\n",
       "      <td>-7.760000</td>\n",
       "      <td>-2.540000</td>\n",
       "      <td>-0.040000</td>\n",
       "      <td>7.9140</td>\n",
       "      <td>7.589000</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.35</td>\n",
       "      <td>7.6252</td>\n",
       "      <td>0.47</td>\n",
       "      <td>540.540527</td>\n",
       "      <td>7274.275879</td>\n",
       "      <td>-1.114141</td>\n",
       "      <td>-1.038942</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107529</th>\n",
       "      <td>6.84</td>\n",
       "      <td>358.819488</td>\n",
       "      <td>-31.884274</td>\n",
       "      <td>3.21</td>\n",
       "      <td>17.810000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>-0.030000</td>\n",
       "      <td>6.7320</td>\n",
       "      <td>6.820000</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>6.8157</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>311.526489</td>\n",
       "      <td>10878.980469</td>\n",
       "      <td>-0.627475</td>\n",
       "      <td>-0.651775</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107544</th>\n",
       "      <td>9.44</td>\n",
       "      <td>359.746582</td>\n",
       "      <td>-29.915969</td>\n",
       "      <td>9.44</td>\n",
       "      <td>180.160000</td>\n",
       "      <td>-114.480000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>10.0770</td>\n",
       "      <td>9.541000</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.62</td>\n",
       "      <td>9.5735</td>\n",
       "      <td>0.62</td>\n",
       "      <td>105.932205</td>\n",
       "      <td>6069.651367</td>\n",
       "      <td>4.314859</td>\n",
       "      <td>4.448360</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107545</th>\n",
       "      <td>8.37</td>\n",
       "      <td>359.773830</td>\n",
       "      <td>55.956112</td>\n",
       "      <td>2.43</td>\n",
       "      <td>7.850000</td>\n",
       "      <td>-2.680000</td>\n",
       "      <td>-0.340000</td>\n",
       "      <td>8.3880</td>\n",
       "      <td>8.364000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.03</td>\n",
       "      <td>8.3813</td>\n",
       "      <td>0.03</td>\n",
       "      <td>411.522644</td>\n",
       "      <td>9760.000000</td>\n",
       "      <td>0.298032</td>\n",
       "      <td>0.309332</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107546</th>\n",
       "      <td>7.87</td>\n",
       "      <td>359.794345</td>\n",
       "      <td>74.807249</td>\n",
       "      <td>7.36</td>\n",
       "      <td>23.250000</td>\n",
       "      <td>-1.550000</td>\n",
       "      <td>-0.190000</td>\n",
       "      <td>8.3210</td>\n",
       "      <td>7.993000</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.35</td>\n",
       "      <td>7.9410</td>\n",
       "      <td>0.35</td>\n",
       "      <td>135.869568</td>\n",
       "      <td>7317.908691</td>\n",
       "      <td>2.204389</td>\n",
       "      <td>2.275389</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107548</th>\n",
       "      <td>9.93</td>\n",
       "      <td>359.948880</td>\n",
       "      <td>50.112499</td>\n",
       "      <td>19.39</td>\n",
       "      <td>434.100000</td>\n",
       "      <td>9.560000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>11.1730</td>\n",
       "      <td>10.021000</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.90</td>\n",
       "      <td>10.0926</td>\n",
       "      <td>0.90</td>\n",
       "      <td>51.572975</td>\n",
       "      <td>4866.096680</td>\n",
       "      <td>6.367889</td>\n",
       "      <td>6.530489</td>\n",
       "      <td>K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104783 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Vmag       RAdeg      DEdeg    Plx        pmRA        pmDE     DE:RA  \\\n",
       "0       8.13   38.205924  61.378360   1.47   -2.340000   -0.720000 -0.200000   \n",
       "1       8.46   38.335785  61.521721   2.13   -0.080000   -2.360000 -0.170000   \n",
       "2       8.85  168.619473 -61.344204  10.99  -65.702143   -6.615714  0.142143   \n",
       "3       2.21  120.896126 -40.003188   2.33  -30.820000   16.770000 -0.070000   \n",
       "4       7.55  303.138025  40.268185   1.85   -7.760000   -2.540000 -0.040000   \n",
       "...      ...         ...        ...    ...         ...         ...       ...   \n",
       "107529  6.84  358.819488 -31.884274   3.21   17.810000    1.580000 -0.030000   \n",
       "107544  9.44  359.746582 -29.915969   9.44  180.160000 -114.480000 -0.050000   \n",
       "107545  8.37  359.773830  55.956112   2.43    7.850000   -2.680000 -0.340000   \n",
       "107546  7.87  359.794345  74.807249   7.36   23.250000   -1.550000 -0.190000   \n",
       "107548  9.93  359.948880  50.112499  19.39  434.100000    9.560000 -0.200000   \n",
       "\n",
       "          BTmag      VTmag    B-V   V-I    Hpmag  (V-I)red           d  \\\n",
       "0        8.9100   8.223000  0.635  0.70   8.2639      0.66  680.272095   \n",
       "1        8.8750   8.493000  0.362  0.42   8.5436      0.41  469.483582   \n",
       "2        9.1995   8.393071  0.954  0.94   9.0175      0.94   90.991814   \n",
       "3        1.9570   2.189000 -0.269 -0.22   2.1364     -0.22  429.184540   \n",
       "4        7.9140   7.589000  0.309  0.35   7.6252      0.47  540.540527   \n",
       "...         ...        ...    ...   ...      ...       ...         ...   \n",
       "107529   6.7320   6.820000 -0.080 -0.06   6.8157     -0.06  311.526489   \n",
       "107544  10.0770   9.541000  0.542  0.62   9.5735      0.62  105.932205   \n",
       "107545   8.3880   8.364000  0.010  0.03   8.3813      0.03  411.522644   \n",
       "107546   8.3210   7.993000  0.302  0.35   7.9410      0.35  135.869568   \n",
       "107548  11.1730  10.021000  0.890  0.90  10.0926      0.90   51.572975   \n",
       "\n",
       "                   T       M_v     M_Hip Tipo_espectral  \n",
       "0        5693.333496 -1.033413 -0.899513              O  \n",
       "1        6960.065430  0.101898  0.185498              O  \n",
       "2        4694.887207  4.054989  4.222488              O  \n",
       "3       14328.858398 -5.953221 -6.026821              O  \n",
       "4        7274.275879 -1.114141 -1.038942              O  \n",
       "...              ...       ...       ...            ...  \n",
       "107529  10878.980469 -0.627475 -0.651775              A  \n",
       "107544   6069.651367  4.314859  4.448360              A  \n",
       "107545   9760.000000  0.298032  0.309332              A  \n",
       "107546   7317.908691  2.204389  2.275389              A  \n",
       "107548   4866.096680  6.367889  6.530489              K  \n",
       "\n",
       "[104783 rows x 18 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aplicamos un encoder a nuestro dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "for column in df:\n",
    "    df[column] = le.fit_transform(df[column])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Vmag','RAdeg', 'DEdeg', 'Plx', 'pmRA', 'pmDE','DE:RA', 'BTmag','VTmag', 'B-V', 'V-I','Hpmag','(V-I)red', 'd', 'T', 'M_v', 'M_Hip']]\n",
    "y = df['Tipo_espectral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "modelo = LinearRegression()\n",
    "modelo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.41151913047852934\n",
      "R2: 0.810754528543708\n",
      "MAE: 0.4938550046656451\n",
      "RMSE: 0.6414975685679014\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Hacer predicciones en los datos de prueba\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "# Calcular las métricas\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Imprimir las métricas\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R2:\", r2)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m314\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=314)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "logistic = LogisticRegression(solver='lbfgs', max_iter=3000) \n",
    "logistic.fit(X_train, y_train) \n",
    "predictions_LR= logistic.predict(X_test) \n",
    "model_RF = RandomForestClassifier(n_estimators=100, max_depth=6, random_state=41) \n",
    "model_RF.fit(X_train, y_train) \n",
    "predictions_RF = model_RF.predict(X_test) \n",
    "KNN_classifier = KNeighborsClassifier(n_neighbors=2) \n",
    "KNN_classifier.fit(X_train, y_train) \n",
    "predictions_KNN = KNN_classifier.predict(X_test) \n",
    "model_GB = GradientBoostingClassifier(min_samples_leaf=5,max_leaf_nodes=5) \n",
    "model_GB.fit(X_train, y_train) \n",
    "predictions_GB = model_GB.predict(X_test) \n",
    "model_XGB = XGBClassifier(learning_rate=0.005, use_label_encoder=False, n_estimators=3500, max_depth=4, min_child_weight=0, gamma=0.6, subsample=0.7, colsample_bytree=0.7, objective='reg:squarederror', nthread=-1, seed=27, reg_alpha=0.00006, random_state=30)\n",
    "model_XGB.fit(X_train, y_train) \n",
    "predictions_XGB = model_XGB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:  0.7712275726672847\n",
      "Random Forest:  0.8109968915307848\n",
      "K-Nearest-Neighbor:  0.7230599334678519\n",
      "Gradient Boosting:  0.8271936521786551\n",
      "XGBoost:  0.8441947974041555\n",
      "Mean:  0.7953345694497463\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression: \", logistic.score(X_train, y_train))\n",
    "\n",
    "print(\"Random Forest: \", model_RF.score(X_train, y_train))\n",
    "\n",
    "print(\"K-Nearest-Neighbor: \", KNN_classifier.score(X_train, y_train))\n",
    "\n",
    "print(\"Gradient Boosting: \", model_GB.score(X_train, y_train))\n",
    "\n",
    "print(\"XGBoost: \", model_XGB.score(X_train, y_train))\n",
    "\n",
    "print(\"Mean: \", (logistic.score(X_train, y_train) + model_RF.score(X_train, y_train) + KNN_classifier.score(X_train, y_train) + model_GB.score(X_train, y_train) + model_XGB.score(X_train, y_train)) / 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceso con las clases espectrales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_parquet('../data/clase_espectral.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.dropna(subset=['Clase_espectral']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mquiquevasallo\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/enriquebook/Data_Analysis/Hipparcos/notebooks/wandb/run-20230429_165030-7bj69gda</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/quiquevasallo/Clasificaci%C3%B3n%20Hipparcos/runs/7bj69gda' target=\"_blank\">decent-universe-1</a></strong> to <a href='https://wandb.ai/quiquevasallo/Clasificaci%C3%B3n%20Hipparcos' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/quiquevasallo/Clasificaci%C3%B3n%20Hipparcos' target=\"_blank\">https://wandb.ai/quiquevasallo/Clasificaci%C3%B3n%20Hipparcos</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/quiquevasallo/Clasificaci%C3%B3n%20Hipparcos/runs/7bj69gda' target=\"_blank\">https://wandb.ai/quiquevasallo/Clasificaci%C3%B3n%20Hipparcos/runs/7bj69gda</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/quiquevasallo/Clasificaci%C3%B3n%20Hipparcos/runs/7bj69gda?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x17e0a37f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"Clasificación Hipparcos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = wandb.config\n",
    "config.max_iter = 100000\n",
    "config.tol = 1e-4\n",
    "config.random_state = 314"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/2cl9nrjs74bc3y72c8n3j2k80000gp/T/ipykernel_89585/499825705.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[column] = le.fit_transform(df2[column])\n",
      "/var/folders/l7/2cl9nrjs74bc3y72c8n3j2k80000gp/T/ipykernel_89585/499825705.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[column] = le.fit_transform(df2[column])\n",
      "/var/folders/l7/2cl9nrjs74bc3y72c8n3j2k80000gp/T/ipykernel_89585/499825705.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[column] = le.fit_transform(df2[column])\n",
      "/var/folders/l7/2cl9nrjs74bc3y72c8n3j2k80000gp/T/ipykernel_89585/499825705.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[column] = le.fit_transform(df2[column])\n",
      "/var/folders/l7/2cl9nrjs74bc3y72c8n3j2k80000gp/T/ipykernel_89585/499825705.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[column] = le.fit_transform(df2[column])\n",
      "/var/folders/l7/2cl9nrjs74bc3y72c8n3j2k80000gp/T/ipykernel_89585/499825705.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[column] = le.fit_transform(df2[column])\n",
      "/var/folders/l7/2cl9nrjs74bc3y72c8n3j2k80000gp/T/ipykernel_89585/499825705.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[column] = le.fit_transform(df2[column])\n",
      "/var/folders/l7/2cl9nrjs74bc3y72c8n3j2k80000gp/T/ipykernel_89585/499825705.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[column] = le.fit_transform(df2[column])\n",
      "/var/folders/l7/2cl9nrjs74bc3y72c8n3j2k80000gp/T/ipykernel_89585/499825705.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[column] = le.fit_transform(df2[column])\n",
      "/var/folders/l7/2cl9nrjs74bc3y72c8n3j2k80000gp/T/ipykernel_89585/499825705.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[column] = le.fit_transform(df2[column])\n",
      "/var/folders/l7/2cl9nrjs74bc3y72c8n3j2k80000gp/T/ipykernel_89585/499825705.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[column] = le.fit_transform(df2[column])\n",
      "/var/folders/l7/2cl9nrjs74bc3y72c8n3j2k80000gp/T/ipykernel_89585/499825705.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[column] = le.fit_transform(df2[column])\n",
      "/var/folders/l7/2cl9nrjs74bc3y72c8n3j2k80000gp/T/ipykernel_89585/499825705.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[column] = le.fit_transform(df2[column])\n",
      "/var/folders/l7/2cl9nrjs74bc3y72c8n3j2k80000gp/T/ipykernel_89585/499825705.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[column] = le.fit_transform(df2[column])\n",
      "/var/folders/l7/2cl9nrjs74bc3y72c8n3j2k80000gp/T/ipykernel_89585/499825705.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[column] = le.fit_transform(df2[column])\n",
      "/var/folders/l7/2cl9nrjs74bc3y72c8n3j2k80000gp/T/ipykernel_89585/499825705.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[column] = le.fit_transform(df2[column])\n",
      "/var/folders/l7/2cl9nrjs74bc3y72c8n3j2k80000gp/T/ipykernel_89585/499825705.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[column] = le.fit_transform(df2[column])\n",
      "/var/folders/l7/2cl9nrjs74bc3y72c8n3j2k80000gp/T/ipykernel_89585/499825705.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[column] = le.fit_transform(df2[column])\n"
     ]
    }
   ],
   "source": [
    "#aplicamos un encoder a nuestro dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "for column in df2:\n",
    "    df2[column] = le.fit_transform(df2[column])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2[['Vmag','RAdeg', 'DEdeg', 'Plx', 'pmRA', 'pmDE','DE:RA', 'BTmag','VTmag', 'B-V', 'V-I','Hpmag','(V-I)red', 'd', 'T', 'M_v', 'M_Hip']]\n",
    "y = df2['Clase_espectral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enriquebook/Data_Analysis/myenv/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.6, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.005, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "              min_child_weight=0, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=3500, n_jobs=None, nthread=-1,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.6, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.005, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "              min_child_weight=0, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=3500, n_jobs=None, nthread=-1,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.7, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.6, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.005, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "              min_child_weight=0, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=3500, n_jobs=None, nthread=-1,\n",
       "              num_parallel_tree=None, objective='multi:softprob', ...)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_XGB = XGBClassifier(learning_rate=0.005, use_label_encoder=False, n_estimators=3500, max_depth=4, min_child_weight=0, gamma=0.6, subsample=0.7, colsample_bytree=0.7, objective='reg:squarederror', nthread=-1, seed=27, reg_alpha=0.00006, random_state=30)\n",
    "model_XGB.fit(X_train, y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_XGB.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_XGB.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m save_model(model_XGB, \u001b[39m'\u001b[39m\u001b[39mhip_XGB\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'save_model' is not defined"
     ]
    }
   ],
   "source": [
    "save_model(model_XGB, 'hip_XGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logistic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m learning_curve\n\u001b[0;32m----> 3\u001b[0m learning_curve(logistic, X_train, y_train, cv\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_learning_curve\u001b[39m(estimator, title, X, y, ylim\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, cv\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, train_sizes\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mlinspace(\u001b[39m.1\u001b[39m, \u001b[39m1.0\u001b[39m, \u001b[39m5\u001b[39m)):\n\u001b[1;32m      6\u001b[0m     plt\u001b[39m.\u001b[39mfigure()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logistic' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "learning_curve(logistic, X_train, y_train, cv=10, n_jobs=-1)\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Ejemplos de entrenamiento\")\n",
    "    plt.ylabel(\"Puntuación\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Ejemplos de Entrenamiento\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Validación cruzada de los puntos de datos\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "plot_learning_curve(logistic, \"Logistic Regression\", X_train, y_train, cv=10, n_jobs=-1)\n",
    "plot_learning_curve(model_RF, \"Random Forest\", X_train, y_train, cv=10, n_jobs=-1)\n",
    "plot_learning_curve(KNN_classifier, \"K-Nearest-Neighbor\", X_train, y_train, cv=10, n_jobs=-1)\n",
    "plot_learning_curve(model_GB, \"Gradient Boosting\", X_train, y_train, cv=10, n_jobs=-1)\n",
    "plot_learning_curve(model_XGB, \"XGBoost\", X_train, y_train, cv=10, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado en un archivo pkl\n",
    "with open('../output/hip_XGB.pkl', 'wb') as f:\n",
    "    pickle.dump(model_XGB, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Crear el archivo .pkl para guardar el modelo\n",
    "# with open('modelo_arima.pkl', 'wb') as archivo:\n",
    "#     # Guardar el modelo en el archivo .pkl\n",
    "#     pickle.dump(modelo_arima_fit, archivo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
